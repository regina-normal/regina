diff --git a/engine/libnormaliz/HilbertSeries.cpp b/engine/libnormaliz/HilbertSeries.cpp
index d0cf8c825..36035b1c4 100644
--- a/engine/libnormaliz/HilbertSeries.cpp
+++ b/engine/libnormaliz/HilbertSeries.cpp
@@ -350,12 +350,12 @@ bool HilbertSeries::get_period_bounded() const {
     return period_bounded;
 }
 // add another HilbertSeries to this
-void HilbertSeries::add(const vector<num_t>& num, const vector<denom_t>& gen_degrees) {
+void HilbertSeries::add(const vector<num_t>& num_, const vector<denom_t>& gen_degrees) {
     vector<denom_t> sorted_gd(gen_degrees);
     sort(sorted_gd.begin(), sorted_gd.end());
     if (gen_degrees.size() > 0)
         assert(sorted_gd[0] > 0);  // TODO InputException?
-    poly_add_to(denom_classes[sorted_gd], num);
+    poly_add_to(denom_classes[sorted_gd], num_);
     if (denom_classes.size() > DENOM_CLASSES_BOUND)
         collectData();
     is_simplified = false;
@@ -535,12 +535,12 @@ void HilbertSeries::simplify() const {
             long k = 1;
             bool empty = true;
             vector<mpz_class> existing_factor(1, 1);  // collects the existing cyclotomic gactors in the denom
-            for (auto& it : cdenom) {                 // with multiplicvity 1
-                if (it.second > 0) {
+            for (auto& d : cdenom) {                 // with multiplicvity 1
+                if (d.second > 0) {
                     empty = false;
-                    k = libnormaliz::lcm(k, it.first);
-                    existing_factor = poly_mult(existing_factor, cyclotomicPoly<mpz_class>(it.first));
-                    it.second--;
+                    k = libnormaliz::lcm(k, d.first);
+                    existing_factor = poly_mult(existing_factor, cyclotomicPoly<mpz_class>(d.first));
+                    d.second--;
                 }
             }
             if (empty)
@@ -668,7 +668,7 @@ void HilbertSeries::computeHilbertQuasiPolynomial() const {
     long reduced_period;
     if (nr_coeff_quasipol >= 0) {
         reduced_period = 1;
-        for (long j = 0; j < nr_coeff_quasipol; ++j)
+        for (j = 0; j < nr_coeff_quasipol; ++j)
             reduced_period = lcm(reduced_period, denom_vec[j]);
     }
     else
@@ -727,9 +727,9 @@ void HilbertSeries::computeHilbertQuasiPolynomial() const {
     if (nr_coeff_quasipol >= 0)
         delete_coeff = (long)quasi_poly[0].size() - nr_coeff_quasipol;
 
-    for (auto& i : quasi_poly)  // delete coefficients that have not been computed completely
-        for (long j = 0; j < delete_coeff; ++j)
-            i[j] = 0;
+    for (auto& p : quasi_poly)  // delete coefficients that have not been computed completely
+        for (j = 0; j < delete_coeff; ++j)
+            p[j] = 0;
 
     if (verbose && period > 1) {
         verboseOutput() << " done." << endl;
@@ -754,8 +754,8 @@ long HilbertSeries::get_expansion_degree() const {
     return expansion_degree;
 }
 
-void HilbertSeries::set_expansion_degree(long degree) {
-    expansion_degree = degree;
+void HilbertSeries::set_expansion_degree(long degree_) {
+    expansion_degree = degree_;
 }
 
 vector<mpz_class> HilbertSeries::expand_denom() const {
diff --git a/engine/libnormaliz/chunk.cpp b/engine/libnormaliz/chunk.cpp
index 71d693fe1..7f974069a 100644
--- a/engine/libnormaliz/chunk.cpp
+++ b/engine/libnormaliz/chunk.cpp
@@ -199,10 +199,8 @@ void chunk() {
 void add_chunks(const string& project) {
     size_t nr_blocks;
 
-    string name_in = project + ".basic.data";
-    const char* file_in = name_in.c_str();
     ifstream in;
-    in.open(file_in, ifstream::in);
+    in.open(project + ".basic.data", ifstream::in);
     if (in.is_open() == false) {
         throw BadInputException("Cannot find basic.data");
     }
@@ -223,22 +221,19 @@ void add_chunks(const string& project) {
     cout << "Summing " << nr_blocks << " partial multiplicities" << endl;
     for (size_t i = 0; i < nr_blocks; ++i) {
         cout << "Reading block " << i << endl;
-        string name_in = project + ".mult." + to_string(i);
-        const char* file_in = name_in.c_str();
-        ifstream in;
-        in.open(file_in, ifstream::in);
-        string type;
-        in >> type;
+        ifstream in_block;
+        in_block.open(project + ".mult." + to_string(i), ifstream::in);
+        in_block >> type;
         if (type != "multiplicity") {
             throw BadInputException("spoiled mult " + to_string(i));
         }
         size_t this_chunk;
-        in >> this_chunk;
+        in_block >> this_chunk;
         if (i != this_chunk) {
             throw BadInputException("spoiled mult " + to_string(i));
         }
         mpq_class mult;
-        in >> mult;
+        in_block >> mult;
         total_mult += mult;
     }
     cout << "Toatl miultiplicity" << endl;
diff --git a/engine/libnormaliz/cone.cpp b/engine/libnormaliz/cone.cpp
index 6be5d5b07..1337b3ed6 100644
--- a/engine/libnormaliz/cone.cpp
+++ b/engine/libnormaliz/cone.cpp
@@ -446,19 +446,19 @@ InputMap<Integer> Cone<Integer>::mpqclass_input_to_integer(
     // special treatment of polytope. We convert it o cone
     // and define the grading
     if (contains(multi_input_data, Type::polytope)) {
-        size_t dim;
+        size_t cone_dim;
         if (multi_input_data[Type::polytope].nr_of_rows() > 0) {
-            dim = multi_input_data[Type::polytope][0].size() + 1;
-            Matrix<Integer> grading(0,dim);
-            grading.append(vector<Integer>(dim));
-            grading[0][dim - 1] = 1;
+            cone_dim = multi_input_data[Type::polytope][0].size() + 1;
+            Matrix<Integer> grading(0,cone_dim);
+            grading.append(vector<Integer>(cone_dim));
+            grading[0][cone_dim - 1] = 1;
             multi_input_data_ZZ[Type::grading] = grading;
         }
         vector<vector<mpq_class> >  Help = multi_input_data[Type::polytope].get_elements();
         multi_input_data.erase(Type::polytope);
         for (size_t i = 0; i < Help.size(); ++i) {
-            Help[i].resize(dim);
-            Help[i][dim - 1] = 1;
+            Help[i].resize(cone_dim);
+            Help[i][cone_dim - 1] = 1;
         }
         multi_input_data[Type::cone]=Matrix<mpq_class>(Help);
     }
@@ -494,10 +494,10 @@ Matrix<Integer> sign_inequalities(const Matrix<Integer>& Signs) {
     if (Signs.nr_of_rows() != 1) {
         throw BadInputException("ERROR: Bad signs matrix, has " + toString(Signs.nr_of_rows()) + " rows (should be 1)!");
     }
-    size_t dim = Signs[0].size();
-    Matrix<Integer> Inequ(0, dim);
-    vector<Integer> ineq(dim, 0);
-    for (size_t i = 0; i < dim; i++) {
+    size_t ineq_dim = Signs[0].size();
+    Matrix<Integer> Inequ(0, ineq_dim);
+    vector<Integer> ineq(ineq_dim, 0);
+    for (size_t i = 0; i < ineq_dim; i++) {
         Integer sign = Signs[0][i];
         if (sign == 1 || sign == -1) {
             ineq[i] = sign;
@@ -516,11 +516,11 @@ Matrix<Integer> strict_sign_inequalities(const Matrix<Integer>& Signs) {
     if (Signs.nr_of_rows() != 1) {
         throw BadInputException("ERROR: Bad signs matrix, has " + toString(Signs.nr_of_rows()) + " rows (should be 1)!");
     }
-    size_t dim = Signs[0].size();
-    Matrix<Integer> Inequ(0, dim);
-    vector<Integer> ineq(dim, 0);
-    ineq[dim - 1] = -1;
-    for (size_t i = 0; i < dim - 1; i++) {  // last component of strict_signs always 0
+    size_t ineq_dim = Signs[0].size();
+    Matrix<Integer> Inequ(0, ineq_dim);
+    vector<Integer> ineq(ineq_dim, 0);
+    ineq[ineq_dim - 1] = -1;
+    for (size_t i = 0; i < ineq_dim - 1; i++) {  // last component of strict_signs always 0
         Integer sign = Signs[0][i];
         if (sign == 1 || sign == -1) {
             ineq[i] = sign;
@@ -881,7 +881,7 @@ void Cone<Integer>::process_multi_input_inner(InputMap<Integer>& multi_input_dat
     }
     if (contains(multi_input_data, Type::open_facets)) {
         size_t allowed = 0;
-        auto it = multi_input_data.begin();
+        it = multi_input_data.begin();
         for (; it != multi_input_data.end(); ++it) {
             switch (it->first) {
                 case Type::open_facets:
@@ -1702,12 +1702,12 @@ void Cone<Integer>::convert_equations_to_inequalties(){
 
 template <typename Integer>
 void Cone<Integer>::process_lattice_data(const Matrix<Integer>& LatticeGenerators,
-                                         Matrix<Integer>& Congruences,
-                                         Matrix<Integer>& Equations) {
+                                         Matrix<Integer>& LatticeCongruences,
+                                         Matrix<Integer>& LatticeEquations) {
     if (!BC_set)
         compose_basis_change(Sublattice_Representation<Integer>(dim));
 
-    bool no_constraints = (Congruences.nr_of_rows() == 0) && (Equations.nr_of_rows() == 0);
+    bool no_constraints = (LatticeCongruences.nr_of_rows() == 0) && (LatticeEquations.nr_of_rows() == 0);
     bool only_cone_gen = (Generators.nr_of_rows() != 0) && no_constraints && (LatticeGenerators.nr_of_rows() == 0);
 
     INTERRUPT_COMPUTATION_BY_EXCEPTION
@@ -1727,24 +1727,24 @@ void Cone<Integer>::process_lattice_data(const Matrix<Integer>& LatticeGenerator
     }
 
     if (Generators.nr_of_rows() != 0) {
-        Equations.append(Generators.kernel(!using_renf<Integer>()));
+        LatticeEquations.append(Generators.kernel(!using_renf<Integer>()));
     }
 
     if (LatticeGenerators.nr_of_rows() != 0) {
         Sublattice_Representation<Integer> GenSublattice(LatticeGenerators, false);
-        if ((Equations.nr_of_rows() == 0) && (Congruences.nr_of_rows() == 0)) {
+        if ((LatticeEquations.nr_of_rows() == 0) && (LatticeCongruences.nr_of_rows() == 0)) {
             compose_basis_change(GenSublattice);
             return;
         }
-        Congruences.append(GenSublattice.getCongruencesMatrix());
-        Equations.append(GenSublattice.getEquationsMatrix());
+        LatticeCongruences.append(GenSublattice.getCongruencesMatrix());
+        LatticeEquations.append(GenSublattice.getEquationsMatrix());
     }
 
     INTERRUPT_COMPUTATION_BY_EXCEPTION
 
-    if (Congruences.nr_of_rows() > 0) {
+    if (LatticeCongruences.nr_of_rows() > 0) {
         bool zero_modulus;
-        Matrix<Integer> Ker_Basis = Congruences.solve_congruences(zero_modulus);
+        Matrix<Integer> Ker_Basis = LatticeCongruences.solve_congruences(zero_modulus);
         if (zero_modulus) {
             throw BadInputException("Modulus 0 in congruence!");
         }
@@ -1754,8 +1754,8 @@ void Cone<Integer>::process_lattice_data(const Matrix<Integer>& LatticeGenerator
 
     INTERRUPT_COMPUTATION_BY_EXCEPTION
 
-    if (Equations.nr_of_rows() > 0) {
-        Matrix<Integer> Ker_Basis = BasisChange.to_sublattice_dual(Equations).kernel(!using_renf<Integer>());
+    if (LatticeEquations.nr_of_rows() > 0) {
+        Matrix<Integer> Ker_Basis = BasisChange.to_sublattice_dual(LatticeEquations).kernel(!using_renf<Integer>());
         Sublattice_Representation<Integer> Basis_Change(Ker_Basis, true);
         compose_basis_change(Basis_Change);
     }
@@ -1764,8 +1764,8 @@ void Cone<Integer>::process_lattice_data(const Matrix<Integer>& LatticeGenerator
 //---------------------------------------------------------------------------
 
 template <typename Integer>
-void Cone<Integer>::insert_default_inequalities(Matrix<Integer>& Inequalities) {
-    if (Generators.nr_of_rows() == 0 && Inequalities.nr_of_rows() == 0 && !inequalities_in_input) {
+void Cone<Integer>::insert_default_inequalities(Matrix<Integer>& CurrentInequalities) {
+    if (Generators.nr_of_rows() == 0 && CurrentInequalities.nr_of_rows() == 0 && !inequalities_in_input) {
         if (verbose) {
             verboseOutput() << "No inequalities specified in constraint mode, using non-negative orthant." << endl;
         }
@@ -1775,12 +1775,12 @@ void Cone<Integer>::insert_default_inequalities(Matrix<Integer>& Inequalities) {
             size_t matsize = dim;
             if (test == Dehomogenization)  // in this case "last coordinate >= 0" will come in through the dehomogenization
                 matsize = dim - 1;         // we don't check for any other coincidence
-            Inequalities = Matrix<Integer>(matsize, dim);
+            CurrentInequalities = Matrix<Integer>(matsize, dim);
             for (size_t j = 0; j < matsize; ++j)
-                Inequalities[j][j] = 1;
+                CurrentInequalities[j][j] = 1;
         }
         else
-            Inequalities = Matrix<Integer>(dim);
+            CurrentInequalities = Matrix<Integer>(dim);
     }
 }
 
@@ -1792,11 +1792,11 @@ Matrix<Integer> Cone<Integer>::prepare_input_type_2(const Matrix<Integer>& Input
     size_t j;
     size_t nr = Input.nr_of_rows();
     // append a column of 1
-    Matrix<Integer> Generators(nr, dim);
+    Matrix<Integer> GensFromInput(nr, dim);
     for (size_t i = 0; i < nr; i++) {
         for (j = 0; j < dim - 1; j++)
-            Generators[i][j] = Input[i][j];
-        Generators[i][dim - 1] = 1;
+            GensFromInput[i][j] = Input[i][j];
+        GensFromInput[i][dim - 1] = 1;
     }
     // use the added last component as grading
     Grading = vector<Integer>(dim, 0);
@@ -1804,7 +1804,7 @@ Matrix<Integer> Cone<Integer>::prepare_input_type_2(const Matrix<Integer>& Input
     setComputed(ConeProperty::Grading);
     GradingDenom = 1;
     setComputed(ConeProperty::GradingDenom);
-    return Generators;
+    return GensFromInput;
 }
 
 //---------------------------------------------------------------------------
@@ -6572,34 +6572,34 @@ bool Cone<Integer>::check_parallelotope() {
     if (inhomogeneous)
         Supps.remove_row(Grad);
 
-    size_t dim = Supps.nr_of_columns() - 1;  // affine dimension
-    if (Supps.nr_of_rows() != 2 * dim)
+    size_t aff_dim = Supps.nr_of_columns() - 1;  // affine dimension
+    if (Supps.nr_of_rows() != 2 * aff_dim)
         return false;
-    Pair.resize(2 * dim);
-    ParaInPair.resize(2 * dim);
-    for (size_t i = 0; i < 2 * dim; ++i) {
-        Pair[i].resize(dim);
+    Pair.resize(2 * aff_dim);
+    ParaInPair.resize(2 * aff_dim);
+    for (size_t i = 0; i < 2 * aff_dim; ++i) {
+        Pair[i].resize(aff_dim);
         Pair[i].reset();
-        ParaInPair[i].resize(dim);
+        ParaInPair[i].resize(aff_dim);
         ParaInPair[i].reset();
     }
 
-    vector<bool> done(2 * dim);
-    Matrix<Integer> M2(2, dim + 1), M3(3, dim + 1);
+    vector<bool> done(2 * aff_dim);
+    Matrix<Integer> M2(2, aff_dim + 1), M3(3, aff_dim + 1);
     M3[2] = Grad;
     size_t pair_counter = 0;
 
     vector<key_t> Supp_1;  // to find antipodal vertices
     vector<key_t> Supp_2;
 
-    for (size_t i = 0; i < 2 * dim; ++i) {
+    for (size_t i = 0; i < 2 * aff_dim; ++i) {
         if (done[i])
             continue;
         bool parallel_found = false;
         M2[0] = Supps[i];
         M3[0] = Supps[i];
         size_t j = i + 1;
-        for (; j < 2 * dim; ++j) {
+        for (; j < 2 * aff_dim; ++j) {
             if (done[j])
                 continue;
             M2[1] = Supps[j];
@@ -6729,7 +6729,7 @@ nmz_float Cone<Integer>::euclidean_corr_factor() {
     if (get_rank_internal() - BasisMaxSubspace.nr_of_rows() == 0)
         return 1.0;
 
-    Integer GradingDenom = 1;
+    Integer UseGradingDenom = 1;
 
     vector<Integer> Grad;
     if (inhomogeneous)
@@ -6785,7 +6785,7 @@ nmz_float Cone<Integer>::euclidean_corr_factor() {
     convert(Bas, Simplex);
     for (size_t i = 0; i < n; ++i) {
         v_scalar_division(Bas[i], convertTo<nmz_float>(degrees[i]));
-        v_scalar_multiplication(Bas[i], convertTo<nmz_float>(GradingDenom));
+        v_scalar_multiplication(Bas[i], convertTo<nmz_float>(UseGradingDenom));
     }
     // choose an origin, namely Bas[0]
     Matrix<nmz_float> Bas1(n - 1, dim);
@@ -6796,7 +6796,7 @@ nmz_float Cone<Integer>::euclidean_corr_factor() {
     // orthogonalize Bas1
     Matrix<double> G(n, dim);
     Matrix<double> M(n, n);
-    Bas1.GramSchmidt(G, M, 0, static_cast<int>(n - 1));
+    Bas1.GramSchmidt(G, M, 0, n - 1);
     // compute euclidean volume
     nmz_float eucl_vol_simpl = 1;
     for (size_t i = 0; i < n - 1; ++i)
diff --git a/engine/libnormaliz/cone_dual_mode.cpp b/engine/libnormaliz/cone_dual_mode.cpp
index c68c05599..ed8a1dfa0 100644
--- a/engine/libnormaliz/cone_dual_mode.cpp
+++ b/engine/libnormaliz/cone_dual_mode.cpp
@@ -174,7 +174,6 @@ void Cone_Dual_Mode<Integer>::cut_with_halfspace_hilbert_basis(const size_t& hyp
 
     const size_t ReportBound = 100000;
 
-    size_t i;
     int sign;
 
     CandidateList<Integer> Positive_Irred(true), Negative_Irred(true), Neutral_Irred(true);  // for the Hilbert basis elements
@@ -203,7 +202,7 @@ void Cone_Dual_Mode<Integer>::cut_with_halfspace_hilbert_basis(const size_t& hyp
                 sign = -1;
             }
             factor = scalar_product / orientation;  // we reduce all elements by the generator of the halfspace
-            for (i = 0; i < dim; i++) {
+            for (size_t i = 0; i < dim; i++) {
                 h.cand[i] -= sign * factor * old_lin_subspace_half[i];
             }
         }
@@ -235,7 +234,6 @@ void Cone_Dual_Mode<Integer>::cut_with_halfspace_hilbert_basis(const size_t& hyp
         gen0_mindeg = 0;  // sort_deg has already been set > 0 for half_space_gen
     else
         gen0_mindeg = Intermediate_HB.Candidates.begin()->sort_deg;
-    typename list<Candidate<Integer> >::const_iterator hh;
     for (const auto& hh : Intermediate_HB.Candidates)
         if (hh.sort_deg < gen0_mindeg)
             gen0_mindeg = hh.sort_deg;
@@ -349,7 +347,7 @@ void Cone_Dual_Mode<Integer>::cut_with_halfspace_hilbert_basis(const size_t& hyp
 
     vector<CandidateTable<Integer> > Pos_Table, Neg_Table, Neutr_Table;  // for reduction in each thread
 
-    for (long i = 0; i < omp_get_max_threads(); ++i) {
+    for (int i = 0; i < omp_get_max_threads(); ++i) {
         New_Positive_thread[i].dual = true;
         New_Positive_thread[i].verbose = verbose;
         New_Negative_thread[i].dual = true;
@@ -731,17 +729,17 @@ void Cone_Dual_Mode<Integer>::cut_with_halfspace_hilbert_basis(const size_t& hyp
 //---------------------------------------------------------------------------
 
 template <typename Integer>
-Matrix<Integer> Cone_Dual_Mode<Integer>::cut_with_halfspace(const size_t& hyp_counter, const Matrix<Integer>& BasisMaxSubspace) {
+Matrix<Integer> Cone_Dual_Mode<Integer>::cut_with_halfspace(const size_t& hyp_counter, const Matrix<Integer>& Orig_BasisMaxSubspace) {
     INTERRUPT_COMPUTATION_BY_EXCEPTION
 
-    size_t i, rank_subspace = BasisMaxSubspace.nr_of_rows();
+    size_t i, rank_subspace = Orig_BasisMaxSubspace.nr_of_rows();
 
     vector<Integer> restriction, lin_form = SupportHyperplanes[hyp_counter], old_lin_subspace_half;
     bool lifting = false;
     Matrix<Integer> New_BasisMaxSubspace =
-        BasisMaxSubspace;  // the new maximal subspace is the intersection of the old with the new haperplane
+        Orig_BasisMaxSubspace;  // the new maximal subspace is the intersection of the old with the new haperplane
     if (rank_subspace != 0) {
-        restriction = BasisMaxSubspace.MxV(lin_form);  // the restriction of the new linear form to Max_Subspace
+        restriction = Orig_BasisMaxSubspace.MxV(lin_form);  // the restriction of the new linear form to Max_Subspace
         for (i = 0; i < rank_subspace; i++)
             if (restriction[i] != 0)
                 break;
@@ -756,7 +754,7 @@ Matrix<Integer> Cone_Dual_Mode<Integer>::cut_with_halfspace(const size_t& hyp_co
             Matrix<Integer> NewBasisOldMaxSubspace =
                 M.AlmostHermite(dummy_rank).transpose();  // compute kernel of restriction and complementary subspace
 
-            Matrix<Integer> NewBasisOldMaxSubspaceAmbient = NewBasisOldMaxSubspace.multiplication(BasisMaxSubspace);
+            Matrix<Integer> NewBasisOldMaxSubspaceAmbient = NewBasisOldMaxSubspace.multiplication(Orig_BasisMaxSubspace);
             // in coordinates of the ambient space
 
             old_lin_subspace_half = NewBasisOldMaxSubspaceAmbient[0];
@@ -771,7 +769,7 @@ Matrix<Integer> Cone_Dual_Mode<Integer>::cut_with_halfspace(const size_t& hyp_co
             New_BasisMaxSubspace = temp;
         }
     }
-    bool pointed = (BasisMaxSubspace.nr_of_rows() == 0);
+    bool pointed = (Orig_BasisMaxSubspace.nr_of_rows() == 0);
 
     cut_with_halfspace_hilbert_basis(hyp_counter, lifting, old_lin_subspace_half, pointed);
 
@@ -807,7 +805,6 @@ void Cone_Dual_Mode<Integer>::hilbert_basis_dual() {
     if (ExtremeRaysInd.size() > 0) {  // implies that we have transformed everything to a pointed full-dimensional cone
         // must produce the relevant support hyperplanes from the generators
         // since the Hilbert basis may have been truncated
-        vector<Integer> test(SupportHyperplanes.nr_of_rows());
         vector<key_t> key;
         vector<key_t> relevant_sh;
         size_t realdim = Generators.rank();
diff --git a/engine/libnormaliz/descent.cpp b/engine/libnormaliz/descent.cpp
index 3a51754c8..f09302fc7 100644
--- a/engine/libnormaliz/descent.cpp
+++ b/engine/libnormaliz/descent.cpp
@@ -467,7 +467,6 @@ void DescentFace<Integer>::compute(
         bool skip_remaining = false;
         vector<mpq_class> thread_mult(omp_get_max_threads(), 0);
         Matrix<Integer> Embedded_Gens(d, d);
-        Matrix<Integer> Gens_this(d, FF.dim);
 
         std::exception_ptr tmp_exception;
 
diff --git a/engine/libnormaliz/face_lattice.cpp b/engine/libnormaliz/face_lattice.cpp
index 2f6bd35bd..853c9ad71 100644
--- a/engine/libnormaliz/face_lattice.cpp
+++ b/engine/libnormaliz/face_lattice.cpp
@@ -128,7 +128,7 @@ bool face_compare(const pair<dynamic_bitset, FaceInfo>& a, const pair<dynamic_bi
 }
 
 template <typename Integer>
-void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbose, bool change_integer_type) {
+void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbose_, bool change_integer_type) {
     bool bound_codim = false;
     if (face_codim_bound >= 0)
         bound_codim = true;
@@ -145,7 +145,7 @@ void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbo
             nr_simpl++;
         }
     }
-    if (verbose)
+    if (verbose_)
         verboseOutput() << "Cosimplicial gens " << nr_simpl << " of " << nr_gens << endl;
 
     bool use_simple_vert = (10 * nr_simpl > nr_gens);
@@ -209,7 +209,7 @@ void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbo
         if (bound_codim && codimension_so_far > face_codim_bound + 1)
             break;
         size_t nr_faces = WorkFaces.size();
-        if (verbose) {
+        if (verbose_) {
             if (report_written)
                 verboseOutput() << endl;
             verboseOutput() << "codim " << codimension_so_far - 1 << " faces to process " << nr_faces << endl;
@@ -243,7 +243,7 @@ void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbo
                 for (; kkk < Fpos; --Fpos, --F)
                     ;
 
-                if (verbose && nr_faces >= RepBound) {
+                if (verbose_ && nr_faces >= RepBound) {
 #pragma omp critical(VERBOSE)
                     while ((long)(kkk * VERBOSE_STEPS) >= step_x_size) {
                         step_x_size += nr_faces;
@@ -377,13 +377,13 @@ void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbo
                         if (simple)
                             codim_of_face = codimension_so_far;
                         else {
-                            dynamic_bitset Containing(nr_supphyps);
+                            dynamic_bitset FaceContaining(nr_supphyps);
                             for (size_t j = 0; j < nr_supphyps; ++j) {  // beta_F
-                                if (Containing[j] == 0 && Fac->first.is_subset_of(SuppHypInd[j])) {
-                                    Containing[j] = 1;
+                                if (FaceContaining[j] == 0 && Fac->first.is_subset_of(SuppHypInd[j])) {
+                                    FaceContaining[j] = 1;
                                 }
                             }
-                            vector<bool> selection = bitset_to_bool(Containing);
+                            vector<bool> selection = bitset_to_bool(FaceContaining);
                             if (change_integer_type) {
                                 try {
                                     codim_of_face = SuppHyps_MI.submatrix(selection).rank();
@@ -481,7 +481,7 @@ void FaceLattice<Integer>::compute(const long face_codim_bound, const bool verbo
 
     // cout << " Total " << FaceLattice.size() << endl;
 
-    if (verbose) {
+    if (verbose_) {
         verboseOutput() << endl << "Total number of faces computed " << total_nr_faces << endl;
         verboseOutput() << "f-vector " << f_vector;
     }
diff --git a/engine/libnormaliz/full_cone.cpp b/engine/libnormaliz/full_cone.cpp
index cd464ce6b..266f5384b 100644
--- a/engine/libnormaliz/full_cone.cpp
+++ b/engine/libnormaliz/full_cone.cpp
@@ -699,7 +699,6 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
 
     // NEW: new_generator is the index of the generator being inserted
 
-    size_t i;
     size_t subfacet_dim = dim - 2;  // NEW dimension of subfacet
     size_t facet_dim = dim - 1;     // NEW dimension of facet
 
@@ -731,7 +730,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
     dynamic_bitset Gen_BothSides(nr_gen);  // indicator for generators that are in a negative as well as a positive supphyp
     Gen_BothSides = GenInPosHyp & GenInNegHyp;
     vector<key_t> Gen_BothSides_key;
-    for (i = 0; i < nr_gen; ++i) {
+    for (size_t i = 0; i < nr_gen; ++i) {
         if (Gen_BothSides[i])
             Gen_BothSides_key.push_back(static_cast<key_t>(i));
     }
@@ -808,7 +807,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
         size_t nr_RelGen_NegHyp;
 
 #pragma omp for schedule(dynamic)
-        for (i = 0; i < nr_NegSimp; i++) {
+        for (size_t i = 0; i < nr_NegSimp; i++) {
             RelGen_NegHyp = Gen_BothSides & Neg_Simp[i]->GenInHyp;
 
             nr_RelGen_NegHyp = 0;
@@ -901,9 +900,8 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
     cout << "*****************************************" << endl;*/
 #pragma omp parallel
     {
-        size_t i, j, k, nr_RelGen_PosHyp;
+        size_t k, nr_RelGen_PosHyp;
         dynamic_bitset subfacet(dim - 2);
-        auto jj = Neg_Subfacet_Multi_United.begin();
         size_t jjpos = 0;
         int tn = omp_get_ancestor_thread_num(omp_start_level + 1);
 
@@ -911,6 +909,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
         if (nr_NegSubfMult * (nr_NeuSimp + nr_NeuNonSimp + nr_NegNonSimp) <=
             100000000) {  // to prevent a desaster in the double loops,
             bool found;
+            auto jj = Neg_Subfacet_Multi_United.begin();
 
             // This for region cannot throw a NormalizException
 
@@ -924,21 +923,21 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
                 subfacet = (*jj).first;
                 found = false;
                 if (nr_NeuSimp < 100000) {  // to prevent disaster
-                    for (i = 0; i < nr_NeuSimp; i++) {
+                    for (size_t i = 0; i < nr_NeuSimp; i++) {
                         found = subfacet.is_subset_of(Neutral_Simp[i]->GenInHyp);
                         if (found)
                             break;
                     }
                 }
                 if (!found && nr_NeuNonSimp < 100000) {
-                    for (i = 0; i < nr_NeuNonSimp; i++) {
+                    for (size_t i = 0; i < nr_NeuNonSimp; i++) {
                         found = subfacet.is_subset_of(Neutral_Non_Simp[i]->GenInHyp);
                         if (found)
                             break;
                     }
                 }
                 if (!found && nr_NegNonSimp < 100000) {
-                    for (i = 0; i < nr_NegNonSimp; i++) {
+                    for (size_t i = 0; i < nr_NegNonSimp; i++) {
                         found = subfacet.is_subset_of(Neg_Non_Simp[i]->GenInHyp);
                         if (found)
                             break;
@@ -953,9 +952,9 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
 #pragma omp single
         {                                               // remove elements that were found in the previous loop
             auto last_inserted = Neg_Subfacet.begin();  // used to speedup insertion into the new map
-            for (auto jj = Neg_Subfacet_Multi_United.begin(); jj != Neg_Subfacet_Multi_United.end(); ++jj) {
-                if ((*jj).second != -1) {
-                    last_inserted = Neg_Subfacet.insert(last_inserted, *jj);
+            for (const auto& f : Neg_Subfacet_Multi_United) {
+                if (f.second != -1) {
+                    last_inserted = Neg_Subfacet.insert(last_inserted, f);
                 }
             }
             nr_NegSubf = Neg_Subfacet.size();
@@ -990,7 +989,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
 
                 RelGen_PosHyp = Gen_BothSides & Pos_Simp[i]->GenInHyp;
                 nr_RelGen_PosHyp = 0;
-                for (j = 0; j < nr_gen && nr_RelGen_PosHyp <= facet_dim; j++)
+                for (size_t j = 0; j < nr_gen && nr_RelGen_PosHyp <= facet_dim; j++)
                     if (RelGen_PosHyp.test(j)) {
                         key[nr_RelGen_PosHyp] = static_cast<key_t>(j);
                         nr_RelGen_PosHyp++;
@@ -1027,7 +1026,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
 
                 // now PS vs N
 
-                for (j = 0; j < nr_NegNonSimp; j++) {  // search negative facet with common subfacet
+                for (size_t j = 0; j < nr_NegNonSimp; j++) {  // search negative facet with common subfacet
 
                     INTERRUPT_COMPUTATION_BY_EXCEPTION
 
@@ -1067,11 +1066,11 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
             // to the top indeoendently in each thread
 
             list<dynamic_bitset> Facets_0_1_thread;
-            for (i = 0; i < nr_PosNonSimp; ++i)
+            for (size_t i = 0; i < nr_PosNonSimp; ++i)
                 Facets_0_1_thread.push_back(Pos_Non_Simp[i]->GenInHyp);
-            for (i = 0; i < nr_NegNonSimp; ++i)
+            for (size_t i = 0; i < nr_NegNonSimp; ++i)
                 Facets_0_1_thread.push_back(Neg_Non_Simp[i]->GenInHyp);
-            for (i = 0; i < nr_NeuNonSimp; ++i)
+            for (size_t i = 0; i < nr_NeuNonSimp; ++i)
                 Facets_0_1_thread.push_back(Neutral_Non_Simp[i]->GenInHyp);
             size_t nr_NonSimp = nr_PosNonSimp + nr_NegNonSimp + nr_NeuNonSimp;
 
@@ -1094,7 +1093,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
                     INTERRUPT_COMPUTATION_BY_EXCEPTION
 
                     auto jj_map = Neg_Subfacet.begin();  // First the Simp
-                    for (j = 0; j < nr_NegSubf; ++j, ++jj_map) {
+                    for (size_t j = 0; j < nr_NegSubf; ++j, ++jj_map) {
                         if ((*jj_map).second != -1) {  // skip used subfacets
                             if (jj_map->first.is_subset_of(Pos_Non_Simp[i]->GenInHyp)) {
                                 add_hyperplane(new_generator, *Pos_Non_Simp[i], *Neg_Simp[(*jj_map).second], NewHypsNonSimp[i],
@@ -1113,7 +1112,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
                     int last_existing = -1;
                     for (size_t jj = 0; jj < nrGensInCone; jj++)  // we make a "key" of the potential vertices in the intersection
                     {
-                        j = GensInCone[jj];
+                        key_t j = GensInCone[jj];
                         if (RelGen_PosHyp.test(j)) {
                             key[nr_RelGen_PosHyp] = static_cast<key_t>(j);
                             for (size_t kk = last_existing + 1; kk <= jj; kk++)  // used in the extension test
@@ -1135,7 +1134,7 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
                     missing_bound = nr_RelGen_PosHyp - subfacet_dim;  // at most this number of generators can be missing
                                                                       // to have a chance for common subfacet
 
-                    for (j = 0; j < nr_NegNonSimp; j++) {
+                    for (size_t j = 0; j < nr_NegNonSimp; j++) {
                         NegHyp_Pointer = Neg_Non_Simp[j];
 
                         if (PosHyp_Pointer->Ident == NegHyp_Pointer->Mother ||
@@ -1321,10 +1320,10 @@ void Full_Cone<Integer>::find_new_facets(const size_t& new_generator) {
       cout << "Matches " << NrMatches << " pot. common subf " << NrCSF << " rank test " <<  NrRank << " comp test "
         << NrComp << " neww hyps " << NrNewF << endl; */
 
-    for (i = 0; i < nr_PosSimp; i++)
+    for (size_t i = 0; i < nr_PosSimp; i++)
         Facets.splice(Facets.end(), NewHypsSimp[i]);
 
-    for (i = 0; i < nr_PosNonSimp; i++)
+    for (size_t i = 0; i < nr_PosNonSimp; i++)
         Facets.splice(Facets.end(), NewHypsNonSimp[i]);
 
     // removing the negative hyperplanes
@@ -1604,8 +1603,8 @@ template <typename Integer>
 void Full_Cone<Integer>::store_key(const vector<key_t>& key,
                                    const Integer& height,
                                    const Integer& mother_vol,
-                                   list<SHORTSIMPLEX<Integer>>& Triangulation) {
-    // stores a simplex given by key and height in Triangulation
+                                   list<SHORTSIMPLEX<Integer>>& DestTriangulation) {
+    // stores a simplex given by key and height in DestTriangulation
     // mother_vol is the volume of the simplex to which the new one is attached
 
     SHORTSIMPLEX<Integer> newsimplex;
@@ -1644,7 +1643,7 @@ void Full_Cone<Integer>::store_key(const vector<key_t>& key,
         Top_Cone->triangulation_is_partial = true;
 
     if (keep_triangulation) {
-        Triangulation.push_back(newsimplex);
+        DestTriangulation.push_back(newsimplex);
         return;
     }
 
@@ -1679,11 +1678,11 @@ void Full_Cone<Integer>::store_key(const vector<key_t>& key,
     }              // if empty thread
 
     if (Simpl_available) {
-        Triangulation.splice(Triangulation.end(), Top_Cone->FS[tn], Top_Cone->FS[tn].begin());
-        Triangulation.back() = newsimplex;
+        DestTriangulation.splice(DestTriangulation.end(), Top_Cone->FS[tn], Top_Cone->FS[tn].begin());
+        DestTriangulation.back() = newsimplex;
     }
     else {
-        Triangulation.push_back(newsimplex);
+        DestTriangulation.push_back(newsimplex);
     }
 }
 
@@ -1692,8 +1691,8 @@ template <>
 void Full_Cone<renf_elem_class>::store_key(const vector<key_t>& key,
                                            const renf_elem_class& height,
                                            const renf_elem_class& mother_vol,
-                                           list<SHORTSIMPLEX<renf_elem_class>>& Triangulation) {
-    // stores a simplex given by key and height in Triangulation
+                                           list<SHORTSIMPLEX<renf_elem_class>>& DestTriangulation) {
+    // stores a simplex given by key and height in DestTriangulation
     // mother_vol is the volume of the simplex to which the new one is attached
 
     SHORTSIMPLEX<renf_elem_class> newsimplex;
@@ -1718,7 +1717,7 @@ void Full_Cone<renf_elem_class>::store_key(const vector<key_t>& key,
         Top_Cone->triangulation_is_partial = true;
 
     if (keep_triangulation) {
-        Triangulation.push_back(newsimplex);
+        DestTriangulation.push_back(newsimplex);
         return;
     }
 
@@ -1753,11 +1752,11 @@ void Full_Cone<renf_elem_class>::store_key(const vector<key_t>& key,
     }              // if empty thread
 
     if (Simpl_available) {
-        Triangulation.splice(Triangulation.end(), Top_Cone->FS[tn], Top_Cone->FS[tn].begin());
-        Triangulation.back() = newsimplex;
+        DestTriangulation.splice(DestTriangulation.end(), Top_Cone->FS[tn], Top_Cone->FS[tn].begin());
+        DestTriangulation.back() = newsimplex;
     }
     else {
-        Triangulation.push_back(newsimplex);
+        DestTriangulation.push_back(newsimplex);
     }
 }
 #endif
@@ -1816,7 +1815,7 @@ void Full_Cone<Integer>::small_vs_large(const size_t new_generator) {
 
         // we first treat it as small pyramid
         auto cl0 = chrono::high_resolution_clock::now();
-        process_pyramid(Pyramid_key, new_generator, store_level, 0, true, hyp,
+        process_pyramid(Pyramid_key, new_generator, 0, true, hyp,
                         start_level);  // is recursive, 0 blocks triangulation
         auto cl1 = chrono::high_resolution_clock::now();
         time_of_small_pyr[Pyramid_key.size()] += cl1 - cl0;
@@ -2036,10 +2035,10 @@ void Full_Cone<Integer>::process_pyramids(const size_t new_generator, const bool
 
                 // now we can store the new pyramid at the right place (or finish the simplicial ones)
                 if (recursive && skip_triang) {  // mark as "do not triangulate"
-                    process_pyramid(Pyramid_key, new_generator, store_level, 0, recursive, hyp, start_level);
+                    process_pyramid(Pyramid_key, new_generator, 0, recursive, hyp, start_level);
                 }
                 else {  // default
-                    process_pyramid(Pyramid_key, new_generator, store_level, -hyp->ValNewGen, recursive, hyp, start_level);
+                    process_pyramid(Pyramid_key, new_generator, -hyp->ValNewGen, recursive, hyp, start_level);
                 }
                 // interrupt parallel execution if it is really parallel
                 // to keep the triangulationand pyramid buffers under control
@@ -2103,7 +2102,6 @@ void Full_Cone<Integer>::process_pyramids(const size_t new_generator, const bool
 template <typename Integer>
 void Full_Cone<Integer>::process_pyramid(const vector<key_t>& Pyramid_key,
                                          const size_t new_generator,
-                                         const size_t store_level,
                                          Integer height,
                                          const bool recursive,
                                          typename list<FACETDATA<Integer>>::iterator hyp,
@@ -2274,13 +2272,11 @@ void Full_Cone<Integer>::find_and_evaluate_start_simplex() {
     // it is absolutely necessary to chooses the start simplex as the lex smallest+
     // in order to be consistent with pyramid decomposition
 
-    size_t i, j;
-
     vector<key_t> key = find_start_simplex();
     assert(key.size() == dim);  // safety heck
     if (verbose) {
         verboseOutput() << "Start simplex ";
-        for (unsigned int i : key)
+        for (key_t i : key)
             verboseOutput() << i + 1 << " ";
         verboseOutput() << endl;
     }
@@ -2302,7 +2298,7 @@ void Full_Cone<Integer>::find_and_evaluate_start_simplex() {
 
     // H.pretty_print(cout);
 
-    for (i = 0; i < dim; i++) {
+    for (size_t i = 0; i < dim; i++) {
         in_triang[key[i]] = true;
         GensInCone.push_back(key[i]);
         if (deg1_triangulation && isComputed(ConeProperty::Grading))
@@ -2327,14 +2323,14 @@ void Full_Cone<Integer>::find_and_evaluate_start_simplex() {
 
     Comparisons.push_back(nrTotalComparisons);
 
-    for (i = 0; i < dim; i++) {
+    for (size_t i = 0; i < dim; i++) {
         FACETDATA<Integer> NewFacet;
         NewFacet.GenInHyp.resize(nr_gen);
         // NewFacet.is_positive_on_all_original_gens = false;
         // NewFacet.is_negative_on_some_original_gen = false;
         swap(NewFacet.Hyp, H[i]);
         NewFacet.simplicial = true;  // indeed, the start simplex is simplicial
-        for (j = 0; j < dim; j++)
+        for (size_t j = 0; j < dim; j++)
             if (j != i)
                 NewFacet.GenInHyp.set(key[j]);
         NewFacet.ValNewGen = -1;                   // must be taken negative since opposite facet
@@ -2347,9 +2343,9 @@ void Full_Cone<Integer>::find_and_evaluate_start_simplex() {
         // define Order_Vector, decides which facets of the simplices are excluded
         Order_Vector = vector<Integer>(dim, 0);
         // Matrix<Integer> G=S.read_generators();
-        for (i = 0; i < dim; i++) {
+        for (size_t i = 0; i < dim; i++) {
             factor = (unsigned long)(1 + i % 10);  // (2*(rand()%(2*dim))+3);
-            for (j = 0; j < dim; j++)
+            for (size_t j = 0; j < dim; j++)
                 Order_Vector[j] += factor * Generators[key[i]][j];
         }
     }
@@ -2367,7 +2363,7 @@ void Full_Cone<Integer>::find_and_evaluate_start_simplex() {
     }
 
     if (do_triangulation) {  // we must prepare the sections of the triangulation
-        for (i = 0; i < dim; i++) {
+        for (size_t i = 0; i < dim; i++) {
             // GensInCone.push_back(key[i]); // now done in first loop since always needed
             TriSectionFirst.push_back(TriangulationBuffer.begin());
             TriSectionLast.push_back(TriangulationBuffer.begin());
@@ -2475,7 +2471,6 @@ void Full_Cone<Integer>::match_neg_hyp_with_pos_hyps(const FACETDATA<Integer>& N
     size_t subfacet_dim = dim - 2;
     size_t nr_missing;
     list<FACETDATA<Integer>> NewHyps;
-    Matrix<Integer> Test(0, dim);
 
     int tn;
     if (omp_get_level() == omp_start_level)
@@ -2760,8 +2755,8 @@ void Full_Cone<Integer>::evaluate_large_rec_pyramids(size_t new_generator) {
                 if (take_time_of_large_pyr) {
                     auto cl_large_1 = chrono::high_resolution_clock::now();
                     size_t nr_pyr_gens = 0;
-                    for (size_t i = 0; i < nr_gen; ++i)
-                        if (p->GenInHyp[i])
+                    for (size_t j = 0; j < nr_gen; ++j)
+                        if (p->GenInHyp[j])
                             nr_pyr_gens++;
                     nr_pyr_gens++;  // for the apex of the pyramid
                     time_of_large_pyr[nr_pyr_gens] += cl_large_1 - cl_large_0;
@@ -3637,8 +3632,7 @@ void Full_Cone<Integer>::compute_multiplicity_or_integral_by_signed_dec() {
     MeasureTime(verbose, "Generic");
 
     if (block_size_hollow_tri > 0) {
-        string file_name = project_name + ".basic.data";
-        ofstream out(file_name.c_str());
+        ofstream out(project_name + ".basic.data");
 
         out << "Project " << project_name << endl;
         out << "Dim " << dim << endl << endl;
@@ -4578,7 +4572,7 @@ void Full_Cone<Integer>::primal_algorithm_initialize() {
     prepare_inclusion_exclusion();
 
     SimplexEval = vector<SimplexEvaluator<Integer>>(omp_get_max_threads(), SimplexEvaluator<Integer>(*this));
-    for (int i = 0; i < SimplexEval.size(); ++i)
+    for (int i = 0; i < static_cast<int>(SimplexEval.size()); ++i)
         SimplexEval[i].set_evaluator_tn(i);
     Results = vector<Collector<Integer>>(omp_get_max_threads(), Collector<Integer>(*this));
     Hilbert_Series.setVerbose(verbose);
@@ -5839,22 +5833,22 @@ void Full_Cone<renf_elem_class>::compute_hsop() {
 template <typename Integer>
 void Full_Cone<Integer>::heights(list<vector<key_t>>& facet_keys,
                                  list<pair<dynamic_bitset, size_t>> faces,
-                                 size_t index,
+                                 size_t use_index,
                                  vector<size_t>& ideal_heights,
                                  size_t max_dim) {
     // since we count the index backwards, this is the actual nr of the extreme ray
 
     do {
-        size_t ER_nr = ideal_heights.size() - index - 1;
+        size_t ER_nr = ideal_heights.size() - use_index - 1;
         // cout << "starting calculation for extreme ray nr " << ER_nr << endl;
         list<pair<dynamic_bitset, size_t>> not_faces;
         auto face_it = faces.begin();
         for (; face_it != faces.end(); ++face_it) {
-            if (face_it->first.test(index)) {  // check whether index is set
+            if (face_it->first.test(use_index)) {  // check whether index is set
                 break;
             }
             // resize not_faces
-            face_it->first.resize(index);
+            face_it->first.resize(use_index);
         }
         not_faces.splice(not_faces.begin(), faces, faces.begin(), face_it);
 
@@ -5905,19 +5899,19 @@ void Full_Cone<Integer>::heights(list<vector<key_t>>& facet_keys,
             }
         }
         // we computed all the heights
-        if (index == 0)
+        if (use_index == 0)
             return;
         // if inner point, we can skip now
 
         // take the union of all faces not containing the current extreme ray
-        dynamic_bitset union_faces(index);
+        dynamic_bitset union_faces(use_index);
         not_faces_it = not_faces.begin();
         for (; not_faces_it != not_faces.end(); ++not_faces_it) {
             union_faces |= not_faces_it->first;  // take the union
         }
         // cout << "Their union: " << union_faces << endl;
         // the not_faces now already have a size one smaller
-        union_faces.resize(index + 1);
+        union_faces.resize(use_index + 1);
         list<pair<dynamic_bitset, size_t>> new_faces;
         // delete all facets which only consist of the previous extreme rays
         auto facet_it = facet_keys.begin();
@@ -5992,7 +5986,7 @@ void Full_Cone<Integer>::heights(list<vector<key_t>>& facet_keys,
                         if (i > ER_nr)
                             intersection.set(ideal_heights.size() - 1 - i, false);
                     }
-                    intersection.resize(index);
+                    intersection.resize(use_index);
                     if (intersection.any()) {
                         // check whether the intersection lies in any of the not_faces
                         not_faces_it = not_faces.begin();
@@ -6042,9 +6036,9 @@ void Full_Cone<Integer>::heights(list<vector<key_t>>& facet_keys,
         //     cout << jt.first << " | " << jt.second << endl;
         // }
 
-        // heights(facet_keys, new_faces, index - 1, ideal_heights, max_dim);
+        // heights(facet_keys, new_faces, use_index - 1, ideal_heights, max_dim);
         swap(faces, new_faces);
-        --index;
+        --use_index;
     } while (true);
 }
 
diff --git a/engine/libnormaliz/full_cone.h b/engine/libnormaliz/full_cone.h
index 9121b8bc4..e4d556948 100644
--- a/engine/libnormaliz/full_cone.h
+++ b/engine/libnormaliz/full_cone.h
@@ -384,7 +384,6 @@ class Full_Cone {
     void process_pyramids(const size_t new_generator, const bool recursive);
     void process_pyramid(const vector<key_t>& Pyramid_key,
                          const size_t new_generator,
-                         const size_t store_level,
                          Integer height,
                          const bool recursive,
                          typename list<FACETDATA<Integer>>::iterator hyp,
diff --git a/engine/libnormaliz/general.cpp b/engine/libnormaliz/general.cpp
index 8d2b9ffd9..04a3f55a8 100644
--- a/engine/libnormaliz/general.cpp
+++ b/engine/libnormaliz/general.cpp
@@ -120,12 +120,12 @@ void StartTime() {
     gettimeofday(&TIME_begin, 0);
 }
 
-void MeasureTime(bool verbose, const std::string& step) {
+void MeasureTime(bool verbose_, const std::string& step) {
     gettimeofday(&TIME_end, 0);
     long seconds = TIME_end.tv_sec - TIME_begin.tv_sec;
     long microseconds = TIME_end.tv_usec - TIME_begin.tv_usec;
     double elapsed = seconds + microseconds * 1e-6;
-    if (verbose)
+    if (verbose_)
         verboseOutput() << step << ": " << elapsed << " sec" << endl;
     TIME_begin = TIME_end;
 }
@@ -133,7 +133,7 @@ void MeasureTime(bool verbose, const std::string& step) {
 void StartTime() {
     return;
 }
-void MeasureTime(bool verbose, const std::string& step) {
+void MeasureTime(bool verbose_, const std::string& step) {
     return;
 }
 #endif
diff --git a/engine/libnormaliz/input.cpp b/engine/libnormaliz/input.cpp
index 4ea1f3eb5..1f7ce452a 100644
--- a/engine/libnormaliz/input.cpp
+++ b/engine/libnormaliz/input.cpp
@@ -838,7 +838,6 @@ InputMap<Number> readNormalizInput(istream& in,
                                                                  string& polynomial,
                                                                  renf_class_shared& number_field) {
     string type_string;
-    long i, j;
     long nr_rows, nr_columns, nr_rows_or_columns;
     InputType input_type;
     Number number;
@@ -1157,9 +1156,9 @@ InputMap<Number> readNormalizInput(istream& in,
                     }
                 }
                 if (dense_matrix) {  // dense matrix
-                    for (i = 0; i < nr_rows; i++) {
+                    for (long i = 0; i < nr_rows; i++) {
                         M[i].resize(nr_columns);
-                        for (j = 0; j < nr_columns; j++) {
+                        for (long j = 0; j < nr_columns; j++) {
                             read_number(in, M[i][j]);
                             // cout << M[i][j] << endl;
                         }
@@ -1186,8 +1185,8 @@ InputMap<Number> readNormalizInput(istream& in,
                 throw BadInputException("Error while reading a " + toString(nr_rows) + "x" + toString(nr_columns) + " matrix !");
             }
             Matrix<Number> M(nr_rows, nr_columns);
-            for (i = 0; i < nr_rows; i++) {
-                for (j = 0; j < nr_columns; j++) {
+            for (long i = 0; i < nr_rows; i++) {
+                for (long j = 0; j < nr_columns; j++) {
                     read_number(in, M[i][j]);
                 }
             }
diff --git a/engine/libnormaliz/matrix.cpp b/engine/libnormaliz/matrix.cpp
index dff52854f..603b36017 100644
--- a/engine/libnormaliz/matrix.cpp
+++ b/engine/libnormaliz/matrix.cpp
@@ -55,11 +55,10 @@ using namespace std;
 // slight efficiency advantage compared to specialized version below
 template <typename Integer>
 vector<size_t> Matrix<Integer>::maximal_decimal_length_columnwise() const {
-    size_t i, j = 0;
     vector<size_t> maxim(nc, 0);
     vector<Integer> pos_max(nc, 0), neg_max(nc, 0);
-    for (i = 0; i < nr; i++) {
-        for (j = 0; j < nc; j++) {
+    for (size_t i = 0; i < nr; i++) {
+        for (size_t j = 0; j < nc; j++) {
             // maxim[j]=max(maxim[j],decimal_length(elem[i][j]));
             if (elem[i][j] < 0) {
                 if (elem[i][j] < neg_max[j])
@@ -260,19 +259,18 @@ void Matrix<Integer>::pretty_print(ostream& out, bool with_row_nr, bool count_fr
         print(out, false);
         return;
     }
-    size_t i, j;
     vector<size_t> max_length = maximal_decimal_length_columnwise();
     size_t max_index_length = decimal_length(nr);
     if (count_from_one)
         max_index_length = decimal_length(nr + 1);
-    for (i = 0; i < nr; i++) {
+    for (size_t i = 0; i < nr; i++) {
         if (with_row_nr) {
             size_t j = i;
             if (count_from_one)
                 j++;
             out << std::setw((int)max_index_length + 1) << std::setprecision(6) << j << ": ";
         }
-        for (j = 0; j < nc; j++) {
+        for (size_t j = 0; j < nc; j++) {
             out << std::setw((int)max_length[j] + 1) << std::setprecision(6) << elem[i][j];
         }
         out << endl;
@@ -3744,15 +3742,14 @@ vector<key_t> Matrix<Integer>::perm_by_weights(const Matrix<Integer>& Weights, v
 template <typename Integer>
 Matrix<Integer> Matrix<Integer>::solve_congruences(bool& zero_modulus) const {
     zero_modulus = false;
-    size_t i, j;
     size_t nr_cong = nr, dim = nc - 1;
     if (nr_cong == 0)
         return Matrix<Integer>(dim);  // give back unit matrix
 
     // add slack variables to convert congruences into equaitions
     Matrix<Integer> Cong_Slack(nr_cong, dim + nr_cong);
-    for (i = 0; i < nr_cong; i++) {
-        for (j = 0; j < dim; j++) {
+    for (size_t i = 0; i < nr_cong; i++) {
+        for (size_t j = 0; j < dim; j++) {
             Cong_Slack[i][j] = elem[i][j];
         }
         Cong_Slack[i][dim + i] = elem[i][dim];
@@ -3848,18 +3845,18 @@ vector<key_t> max_and_min_values(const vector<nmz_float> Values) {
 }
 
 template <typename Integer>
-size_t Matrix<Integer>::extreme_points_first(bool verbose, vector<key_t>& perm) {
+size_t Matrix<Integer>::extreme_points_first(bool verbose_, vector<key_t>& perm) {
     assert(false);
     return 0;
 }
 
 template <>
-size_t Matrix<nmz_float>::extreme_points_first(bool verbose, vector<key_t>& perm) {
+size_t Matrix<nmz_float>::extreme_points_first(bool verbose_, vector<key_t>& perm) {
 
     if (nr == 0)
         return 0;
 
-    if (verbose)
+    if (verbose_)
         verboseOutput() << "Trying to find extreme points" << endl;
 
     size_t nr_extr = 0;
@@ -3946,7 +3943,7 @@ size_t Matrix<nmz_float>::extreme_points_first(bool verbose, vector<key_t>& perm
         else {
             no_success = 0;
             nr_extr += new_hits;
-            if (verbose && counter_100 >= 100) {
+            if (verbose_ && counter_100 >= 100) {
                 verboseOutput() << "Extreme points " << nr_extr << endl;
                 counter_100 = 0;
             }
@@ -4151,15 +4148,15 @@ vector<renf_elem_class> Matrix<renf_elem_class>::optimal_subdivision_point_inner
 // The orthogonal matrix is B
 // Coefficients in M
 template <typename Integer>
-void Matrix<Integer>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, int from, int to) {
+void Matrix<Integer>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, size_t from, size_t to) {
     // from=0;
-    // to= (int) nr_of_rows();
-    assert(to <= (int)nr_of_rows());
+    // to=nr_of_rows();
+    assert(to <= nr_of_rows());
     size_t dim = nr_of_columns();
-    for (int i = from; i < to; ++i) {
+    for (size_t i = from; i < to; ++i) {
         convert(B[i], elem[i]);
         // cout << B[i];
-        for (int j = 0; j < i; ++j) {
+        for (size_t j = 0; j < i; ++j) {
             nmz_float sp = 0;
             for (size_t k = 0; k < dim; ++k) {
                 nmz_float fact;
@@ -4175,18 +4172,18 @@ void Matrix<Integer>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, in
 }
 
 template <>
-void Matrix<mpq_class>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, int from, int to) {
+void Matrix<mpq_class>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, size_t from, size_t to) {
     assert(false);
 
     /*
         // from=0;
-        // to= (int) nr_of_rows();
-        assert(to <= (int) nr_of_rows());
+        // to=nr_of_rows();
+        assert(to <= nr_of_rows());
         size_t dim=nr_of_columns();
-        for(int i=from;i<to;++i){
+        for(size_t i=from;i<to;++i){
             convert(B[i],elem[i]);
             // cout << B[i];
-            for(int j=0;j<i;++j){
+            for(size_t j=0;j<i;++j){
                 nmz_float sp=0;
                 for(size_t k=0;k<dim;++k){
                     nmz_float fact;
@@ -4203,18 +4200,18 @@ void Matrix<mpq_class>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M,
 
 #ifdef ENFNORMALIZ
 template <>
-void Matrix<renf_elem_class>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, int from, int to) {
+void Matrix<renf_elem_class>::GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, size_t from, size_t to) {
     assert(false);
 
     /*
         // from=0;
-        // to= (int) nr_of_rows();
-        assert(to <= (int) nr_of_rows());
+        // to=nr_of_rows();
+        assert(to <= nr_of_rows());
         size_t dim=nr_of_columns();
-        for(int i=from;i<to;++i){
+        for(size_t i=from;i<to;++i){
             convert(B[i],elem[i]);
             // cout << B[i];
-            for(int j=0;j<i;++j){
+            for(size_t j=0;j<i;++j){
                 nmz_float sp=0;
                 for(size_t k=0;k<dim;++k){
                     nmz_float fact;
diff --git a/engine/libnormaliz/matrix.h b/engine/libnormaliz/matrix.h
index ff123df25..88345cc43 100644
--- a/engine/libnormaliz/matrix.h
+++ b/engine/libnormaliz/matrix.h
@@ -531,7 +531,7 @@ class Matrix {
 
     Matrix<Integer> LLL_transpose() const;
 
-    void GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, int from, int to);
+    void GramSchmidt(Matrix<nmz_float>& B, Matrix<nmz_float>& M, size_t from, size_t to);
 
     // check maztrix for defining a projection and using it
 
@@ -654,9 +654,9 @@ Matrix<Number> LLL_red(const Matrix<Number>& U, Matrix<Integer>& T, Matrix<Integ
 
     Lred.GramSchmidt(G, M, 0, 2);
 
-    int i = 1;
+    ssize_t i = 1;
     while (true) {
-        for (int j = i - 1; j >= 0; --j) {
+        for (ssize_t j = i - 1; j >= 0; --j) {
             Integer fact;
             /* cout << "MMMMM " << i << " " << j << " " << M[i][j] << endl;
             cout << i << "---" << G[i];
@@ -692,7 +692,7 @@ Matrix<Number> LLL_red(const Matrix<Number>& U, Matrix<Integer>& T, Matrix<Integ
         }
         else {
             i++;
-            if (i >= n)
+            if (i >= static_cast<ssize_t>(n))
                 break;
             Lred.GramSchmidt(G, M, i, i + 1);
         }
diff --git a/engine/libnormaliz/output.cpp b/engine/libnormaliz/output.cpp
index e381abd7d..b2fdfb21e 100644
--- a/engine/libnormaliz/output.cpp
+++ b/engine/libnormaliz/output.cpp
@@ -47,8 +47,8 @@ using namespace std;
 
 template <typename Integer>
 Output<Integer>::Output() {
-    out = true;
-    inv = false;
+    write_out = true;
+    write_inv = false;
     ext = false;
     esp = false;
     typ = false;
@@ -190,14 +190,14 @@ void Output<renf_elem_class>::set_renf(const renf_class_shared renf, bool is_int
 
 template <typename Integer>
 void Output<Integer>::set_write_out(const bool& flag) {
-    out = flag;
+    write_out = flag;
 }
 
 //---------------------------------------------------------------------------
 
 template <typename Integer>
 void Output<Integer>::set_write_inv(const bool& flag) {
-    inv = flag;
+    write_inv = flag;
 }
 
 //---------------------------------------------------------------------------
@@ -321,8 +321,8 @@ void Output<Integer>::set_write_inc(const bool& flag) {
 
 template <typename Integer>
 void Output<Integer>::set_write_extra_files() {
-    out = true;
-    inv = true;
+    write_out = true;
+    write_inv = true;
     gen = true;
     cst = true;
 }
@@ -331,8 +331,8 @@ void Output<Integer>::set_write_extra_files() {
 
 template <typename Integer>
 void Output<Integer>::set_write_all_files() {
-    out = true;
-    inv = true;
+    write_out = true;
+    write_inv = true;
     ext = true;
     esp = true;
     typ = true;
@@ -440,9 +440,9 @@ void Output<Integer>::write_perms_and_orbits(ofstream& out,
     out << "Cycle decompositions " << endl << endl;
 
     for (size_t i = 0; i < nr_items; ++i) {
-        vector<vector<libnormaliz::key_t> > dec = cycle_decomposition(Perms[i]);
+        vector<vector<libnormaliz::key_t> > decomp = cycle_decomposition(Perms[i]);
         out << "Perm " << i + 1 << ": ";
-        pretty_print_cycle_dec(dec, out);
+        pretty_print_cycle_dec(decomp, out);
     }
     out << endl;
 
@@ -804,7 +804,7 @@ string is_maximal(long a, long b) {
 
 template <typename Integer>
 void Output<Integer>::write_inv_file() const {
-    if (inv == true) {  // printing .inv file
+    if (write_inv == true) {  // printing .inv file
         size_t i;
         string name_open = name + ".inv";  // preparing output files
         const char* file = name_open.c_str();
@@ -1184,7 +1184,7 @@ void Output<Integer>::writeSeries(ofstream& out, const HilbertSeries& HS, string
 
 template <typename Integer>
 void Output<Integer>::write_files() const {
-    size_t i, nr;
+    size_t nr;
     vector<libnormaliz::key_t> rees_ideal_key;
 
     write_precomp();  // only if asked for
@@ -1234,7 +1234,7 @@ void Output<Integer>::write_files() const {
         write_dual_inc();
     }
 
-    if (out == true) {                     // printing .out file
+    if (write_out == true) {                     // printing .out file
         string name_open = name + ".out";  // preparing output files
         const char* file = name_open.c_str();
         ofstream out(file);
@@ -1263,7 +1263,7 @@ void Output<Integer>::write_files() const {
         if (Result->isComputed(ConeProperty::IsReesPrimary) && Result->isComputed(ConeProperty::HilbertBasis)) {
             const Matrix<Integer>& Hilbert_Basis = Result->getHilbertBasisMatrix();
             nr = Hilbert_Basis.nr_of_rows();
-            for (i = 0; i < nr; i++) {
+            for (size_t i = 0; i < nr; i++) {
                 if (Hilbert_Basis[i][dim - 1] == 1) {
                     rees_ideal_key.push_back(static_cast<key_t>(i));
                 }
@@ -1381,7 +1381,7 @@ void Output<Integer>::write_files() const {
                 out << "degrees of extreme rays:" << endl;
                 map<Integer, long> deg_count;
                 vector<Integer> degs = Result->getExtremeRaysMatrix().MxV(Result->getGrading());
-                for (i = 0; i < degs.size(); ++i) {
+                for (size_t i = 0; i < degs.size(); ++i) {
                     deg_count[degs[i] / denom]++;
                 }
                 out << deg_count;
diff --git a/engine/libnormaliz/output.h b/engine/libnormaliz/output.h
index f1629970a..60b938a3d 100644
--- a/engine/libnormaliz/output.h
+++ b/engine/libnormaliz/output.h
@@ -36,8 +36,8 @@ using namespace std;
 template <typename Number>
 class Output {
     string name;
-    bool out;
-    bool inv;
+    bool write_out;
+    bool write_inv;
     bool ext;
     bool esp;
     bool typ;
diff --git a/engine/libnormaliz/simplex.cpp b/engine/libnormaliz/simplex.cpp
index f026f5b86..ddcb35770 100644
--- a/engine/libnormaliz/simplex.cpp
+++ b/engine/libnormaliz/simplex.cpp
@@ -353,15 +353,15 @@ void SimplexEvaluator<Integer>::prepare_inclusion_exclusion_simpl(size_t Deg, Co
 //---------------------------------------------------------------------------
 
 template <typename Integer>
-void SimplexEvaluator<Integer>::update_inhom_hvector(long level_offset, size_t Deg, Collector<Integer>& Coll) {
-    if (level_offset == 1) {
+void SimplexEvaluator<Integer>::update_inhom_hvector(long level_offset_, size_t Deg, Collector<Integer>& Coll) {
+    if (level_offset_ == 1) {
         Coll.inhom_hvector[Deg]++;
         return;
     }
 
     size_t Deg_i;
 
-    assert(level_offset == 0);
+    assert(level_offset_ == 0);
 
     for (size_t i = 0; i < dim; ++i) {
         if (gen_levels[i] == 1) {
@@ -484,8 +484,8 @@ Integer SimplexEvaluator<Integer>::start_evaluation(SHORTSIMPLEX<Integer>& s, Co
             RS_pointers = unit_matrix.submatrix_pointers(Ind0_key);
             LinSys.solve_system_submatrix(Generators, id_key, RS_pointers, GDiag, volume, 0, RS_pointers.size());
             // RS_pointers.size(): all columns of solution replaced by sign vevctors
-            for (size_t i = 0; i < dim; ++i)
-                for (size_t j = dim; j < dim + Ind0_key.size(); ++j)
+            for (i = 0; i < dim; ++i)
+                for (j = dim; j < dim + Ind0_key.size(); ++j)
                     InvGenSelCols[i][Ind0_key[j - dim]] = LinSys[i][j];
 
             v_abs(GDiag);
@@ -554,8 +554,8 @@ Integer SimplexEvaluator<Integer>::start_evaluation(SHORTSIMPLEX<Integer>& s, Co
         if (Ind0_key.size() > 0) {
             RS_pointers = unit_matrix.submatrix_pointers(Ind0_key);
             LinSys.solve_system_submatrix(Generators, id_key, RS_pointers, volume, 0, RS_pointers.size());
-            for (size_t i = 0; i < dim; ++i)
-                for (size_t j = dim; j < dim + Ind0_key.size(); ++j)
+            for (i = 0; i < dim; ++i)
+                for (j = dim; j < dim + Ind0_key.size(); ++j)
                     InvGenSelCols[i][Ind0_key[j - dim]] = LinSys[i][j];
         }
     }
@@ -710,7 +710,7 @@ void SimplexEvaluator<Integer>::evaluate_element(const vector<Integer>& element,
         }
     }
 
-    long level, level_offset = 0;
+    long level, level_offset_ = 0;
     Integer level_Int = 0;
 
     if (C.inhomogeneous) {
@@ -726,10 +726,10 @@ void SimplexEvaluator<Integer>::evaluate_element(const vector<Integer>& element,
         // cout << "Habe ihn" << endl;
 
         if (C.do_h_vector) {
-            level_offset = level;
+            level_offset_ = level;
             for (i = 0; i < dim; i++)
                 if (element[i] == 0 && Excluded[i])
-                    level_offset += gen_levels_long[i];
+                    level_offset_ += gen_levels_long[i];
         }
     }
 
@@ -743,8 +743,8 @@ void SimplexEvaluator<Integer>::evaluate_element(const vector<Integer>& element,
         }
 
         // count point in the h-vector
-        if (C.inhomogeneous && level_offset <= 1)
-            update_inhom_hvector(level_offset, Deg, Coll);
+        if (C.inhomogeneous && level_offset_ <= 1)
+            update_inhom_hvector(level_offset_, Deg, Coll);
         else
             Coll.hvector[Deg]++;
 
@@ -1013,7 +1013,7 @@ void SimplexEvaluator<Integer>::evaluation_loop_parallel() {
 
 #pragma omp parallel
             {
-                int tn = omp_get_thread_num();  // chooses the associated collector Results[tn]
+                int thread = omp_get_thread_num();  // chooses the associated collector Results[thread]
 
 #pragma omp for schedule(dynamic)
                 for (size_t i = 0; i < actual_nr_blocks; ++i) {
@@ -1029,8 +1029,8 @@ void SimplexEvaluator<Integer>::evaluation_loop_parallel() {
                         long block_end = block_start + block_length - 1;
                         if (block_end > (long)nr_elements)
                             block_end = nr_elements;
-                        evaluate_block(block_start, block_end, C_ptr->Results[tn]);
-                        if (C_ptr->Results[tn].candidates_size >= LocalReductionBound)  // >= (not > !! ) if
+                        evaluate_block(block_start, block_end, C_ptr->Results[thread]);
+                        if (C_ptr->Results[thread].candidates_size >= LocalReductionBound)  // >= (not > !! ) if
                             skip_remaining = true;  // LocalReductionBound==ParallelBlockLength
                     } catch (const std::exception&) {
                         tmp_exception = std::current_exception();
diff --git a/engine/libnormaliz/sublattice_representation.h b/engine/libnormaliz/sublattice_representation.h
index af81b80cc..4cd95195b 100644
--- a/engine/libnormaliz/sublattice_representation.h
+++ b/engine/libnormaliz/sublattice_representation.h
@@ -309,7 +309,7 @@ template <typename Integer, typename number>
 void LLL_coordinates_without_1st_col(Sublattice_Representation<Integer>& LLL_Coordinates,
                                      const Matrix<number> Supps,
                                      const Matrix<number> Vertices,
-                                     bool verbose) {
+                                     bool verbose_) {
     // used when the 1st column is the grading or the dehomogenization and should bot be changed
     // Important in project_and_lift
     // Computed SLR is returned in LLL_Coordinates
@@ -328,7 +328,7 @@ void LLL_coordinates_without_1st_col(Sublattice_Representation<Integer>& LLL_Coo
         convert(HelpA, HelpCoord.getEmbeddingMatrix());
         convert(HelpB, HelpCoord.getProjectionMatrix());
         convert(HelpC, HelpCoord.getAnnihilator());
-        if (verbose)
+        if (verbose_)
             verboseOutput() << "LLL based on support hyperplanes" << endl;
     }
     else {  // use Vertices for LLL coordinates
@@ -339,7 +339,7 @@ void LLL_coordinates_without_1st_col(Sublattice_Representation<Integer>& LLL_Coo
         convert(HelpA, HelpCoord.getEmbeddingMatrix());
         convert(HelpB, HelpCoord.getProjectionMatrix());
         convert(HelpC, HelpCoord.getAnnihilator());
-        if (verbose)
+        if (verbose_)
             verboseOutput() << "LLL based on vertices" << endl;
     }
 
diff --git a/engine/libnormaliz/vector_operations.h b/engine/libnormaliz/vector_operations.h
index f3e1da88d..aec429aa2 100644
--- a/engine/libnormaliz/vector_operations.h
+++ b/engine/libnormaliz/vector_operations.h
@@ -503,7 +503,7 @@ void v_el_trans(const vector<Integer>& av, vector<Integer>& bv, const Integer& F
     if (n > 0)
         b[0] += F * a[0];
 
-    for (size_t i = 0; i < bv.size(); ++i)
+    for (i = 0; i < bv.size(); ++i)
         if (!check_range(bv[i]))
             throw ArithmeticException("Vector entry out of range. Imminent danger of arithmetic overflow.");
 }
